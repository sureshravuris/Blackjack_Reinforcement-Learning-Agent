{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNr6wxj3WURjuIdS4cqxTGW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Training a Q Learning Agent in Gymnasium's Blackjack Environment"],"metadata":{"id":"K19cABMcwRRV"}},{"cell_type":"markdown","source":["## Imports and Installs"],"metadata":{"id":"hdija3UgzqNa"}},{"cell_type":"code","source":["!pip install gym gym[atari] gym[accept-rom-license] agilerl accelerate>=0.21.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EN99d6fxuALj","executionInfo":{"status":"ok","timestamp":1730685761192,"user_tz":480,"elapsed":7170,"user":{"displayName":"Alexis Bryan Ambriz","userId":"12219762004133392562"}},"outputId":"cec47b21-0519-4f64-f107-928cd986e878"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: typer 0.12.5 does not provide the extra 'all'\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import os\n","import imageio\n","import gymnasium as gym\n","import numpy as np\n","\n","### These imports will be used to implement the NN Agent ##\n","#import torch\n","#from agilerl.algorithms.td3 import TD3\n","#from agilerl.components.replay_buffer import ReplayBuffer\n","#from agilerl.hpo.mutation import Mutations\n","#from agilerl.hpo.tournament import TournamentSelection\n","#from agilerl.training.train_off_policy import train_off_policy\n","#from agilerl.utils.utils import create_population, make_vect_envs\n","\n","from tqdm import tqdm\n","from __future__ import annotations\n","from collections import defaultdict"],"metadata":{"id":"g-Pz7XjLsdab","executionInfo":{"status":"ok","timestamp":1730685761534,"user_tz":480,"elapsed":345,"user":{"displayName":"Alexis Bryan Ambriz","userId":"12219762004133392562"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["env = gym.make(\"Blackjack-v1\", render_mode=\"rgb_array\")\n","n_episodes = 50_000\n","env = gym.wrappers.RecordEpisodeStatistics(env, deque_size=n_episodes)"],"metadata":{"id":"bfrlHR2ptyTa","executionInfo":{"status":"ok","timestamp":1730685793542,"user_tz":480,"elapsed":2,"user":{"displayName":"Alexis Bryan Ambriz","userId":"12219762004133392562"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["class BlackjackAgent:\n","    def __init__(\n","        self,\n","        env,\n","        learning_rate: float,\n","        initial_epsilon: float,\n","        epsilon_decay: float,\n","        final_epsilon: float,\n","        discount_factor: float = 0.95,\n","    ):\n","        \"\"\"Initialize a Reinforcement Learning agent with an empty dictionary\n","        of state-action values (q_values), a learning rate and an epsilon.\n","\n","        Args:\n","            learning_rate: The learning rate\n","            initial_epsilon: The initial epsilon value\n","            epsilon_decay: The decay for epsilon\n","            final_epsilon: The final epsilon value\n","            discount_factor: The discount factor for computing the Q-value\n","        \"\"\"\n","        self.q_values = defaultdict(lambda: np.zeros(env.action_space.n))\n","\n","        self.lr = learning_rate\n","        self.discount_factor = discount_factor\n","\n","        self.epsilon = initial_epsilon\n","        self.epsilon_decay = epsilon_decay\n","        self.final_epsilon = final_epsilon\n","\n","        self.training_error = []\n","\n","    def get_action(self, env, obs: tuple[int, int, bool]) -> int:\n","        \"\"\"\n","        Returns the best action with probability (1 - epsilon)\n","        otherwise a random action with probability epsilon to ensure exploration.\n","        \"\"\"\n","        # with probability epsilon return a random action to explore the environment\n","        if np.random.random() < self.epsilon:\n","            return env.action_space.sample()\n","\n","        # with probability (1 - epsilon) act greedily (exploit)\n","        else:\n","            return int(np.argmax(self.q_values[obs]))\n","\n","    def update(\n","        self,\n","        obs: tuple[int, int, bool],\n","        action: int,\n","        reward: float,\n","        terminated: bool,\n","        next_obs: tuple[int, int, bool],\n","    ):\n","        \"\"\"Updates the Q-value of an action.\"\"\"\n","        future_q_value = (not terminated) * np.max(self.q_values[next_obs])\n","        temporal_difference = (\n","            reward + self.discount_factor * future_q_value - self.q_values[obs][action]\n","        )\n","\n","        self.q_values[obs][action] = (\n","            self.q_values[obs][action] + self.lr * temporal_difference\n","        )\n","        self.training_error.append(temporal_difference)\n","\n","    def decay_epsilon(self):\n","        self.epsilon = max(self.final_epsilon, self.epsilon - self.epsilon_decay)"],"metadata":{"id":"lSSYeko4W99I","executionInfo":{"status":"ok","timestamp":1730685794470,"user_tz":480,"elapsed":106,"user":{"displayName":"Alexis Bryan Ambriz","userId":"12219762004133392562"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# hyperparameters\n","learning_rate = 0.01\n","start_epsilon = 1.0\n","epsilon_decay = start_epsilon / (n_episodes / 2)  # reduce the exploration over time\n","final_epsilon = 0.1\n","\n","agent = BlackjackAgent(\n","    env=env,\n","    learning_rate=learning_rate,\n","    initial_epsilon=start_epsilon,\n","    epsilon_decay=epsilon_decay,\n","    final_epsilon=final_epsilon,\n",")"],"metadata":{"id":"1l6z0d6cXGmW","executionInfo":{"status":"ok","timestamp":1730685794745,"user_tz":480,"elapsed":159,"user":{"displayName":"Alexis Bryan Ambriz","userId":"12219762004133392562"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def train(agent, env):\n","    best_reward = -float('inf')\n","    for episode in tqdm(range(n_episodes)):\n","        done = False\n","        obs = env.reset()\n","        ### printing the obs for debugging\n","        #print(obs, ' obs')\n","        #print(type(obs), ' obs type')\n","        #print(obs[0][0], ' obs[0]')\n","        #print(obs[0][1], ' obs[1]')\n","        #print(obs[1], ' obs[1]')\n","        #print(type(obs[0]), ' obs[0] type')\n","        #print(type(obs[1]), ' obs[1] type')\n","        total_reward = 0.0\n","        while not done:\n","            action = agent.get_action(env, obs[0])\n","            next_obs, reward, terminated, truncated, info = env.step(action)\n","\n","            agent.update(obs[0], action, reward, terminated, next_obs[0])\n","            done = terminated or truncated\n","\n","            obs = next_obs\n","            total_reward += reward\n","        if total_reward > best_reward:\n","            best_reward = total_reward\n","        print(\"Episode#:{} reward:{} best_reward:{} eps:{}\".format(episode,\n","                                     total_reward, best_reward, agent.epsilon))\n","        agent.decay_epsilon()\n","    # Return the trained policy\n","\n","    return agent.q_values"],"metadata":{"id":"6RkAMvgZuvlu","executionInfo":{"status":"ok","timestamp":1730685794872,"user_tz":480,"elapsed":1,"user":{"displayName":"Alexis Bryan Ambriz","userId":"12219762004133392562"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["learned_policy = train(agent, env)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"14ydXupQVpboR5AvKWSqXcpnFUGmBe4NB"},"id":"MVoJgFRMvTz2","outputId":"9ab9a2b7-caf1-4d7b-c1fa-e27c57e8511e","executionInfo":{"status":"ok","timestamp":1730685852922,"user_tz":480,"elapsed":57795,"user":{"displayName":"Alexis Bryan Ambriz","userId":"12219762004133392562"}}},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["def test(agent, env, policy):\n","    done = False\n","    obs = env.reset()\n","    total_reward = 0.0\n","    while not done:\n","        print(obs[0], ' obs')\n","\n","        action = np.argmax(policy[obs[0]])\n","        next_obs, reward, terminated, truncated, info = env.step(action)\n","        done = terminated or truncated\n","        obs = next_obs\n","        total_reward += reward\n","    return total_reward"],"metadata":{"id":"oR7CvxtGum0V","executionInfo":{"status":"ok","timestamp":1730685855975,"user_tz":480,"elapsed":118,"user":{"displayName":"Alexis Bryan Ambriz","userId":"12219762004133392562"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Uses the Gym Monitor wrapper to evalaute the agent and record video\n","# only one video will be saved\n","\n","# video of the final episode with the episode trigger\n","env = gym.wrappers.RecordVideo(\n","    env, \"./gym_monitor_output\", episode_trigger=lambda x: x == 0)\n","\n","test(agent, env, learned_policy)\n","\n","env.close()"],"metadata":{"id":"HJPj-rXDtlHX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730685856305,"user_tz":480,"elapsed":224,"user":{"displayName":"Alexis Bryan Ambriz","userId":"12219762004133392562"}},"outputId":"3d8d4318-0b67-4a4a-d0b5-fd59567e19a5"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/gym_monitor_output folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n","  logger.warn(\n"]},{"output_type":"stream","name":"stdout","text":["(10, 3, 0)  obs\n","20  obs\n","Moviepy - Building video /content/gym_monitor_output/rl-video-episode-0.mp4.\n","Moviepy - Writing video /content/gym_monitor_output/rl-video-episode-0.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":["                                                  "]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready /content/gym_monitor_output/rl-video-episode-0.mp4\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}]},{"cell_type":"code","source":[],"metadata":{"id":"hQhfvfJb0x6a","executionInfo":{"status":"ok","timestamp":1730685763811,"user_tz":480,"elapsed":208,"user":{"displayName":"Alexis Bryan Ambriz","userId":"12219762004133392562"}}},"execution_count":9,"outputs":[]}]}